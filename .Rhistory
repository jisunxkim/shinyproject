adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
colnames(training)[1] <- "diagnosis"
colnames(testing)[1] <- "diagnosis"
trainset = data.frame(training$diagnosis, training[, startsWith(names(training), "IL")])
testset = data.frame(testing$diagnosis, testing[, startsWith(names(testing), "IL")])
str(trainset)
trainset = data.frame(training$diagnosis, training[, startsWith(names(training), "IL")])
testset = data.frame(testing$diagnosis, testing[, startsWith(names(testing), "IL")])
colnames(trainset)[1] <- "diagnosis"
colnames(testset)[1] <- "diagnosis"
str(trainset)
model1 <- train(y = trainset$diagnosis, x = trainset,
method = "glm")
model1 <- train(trainset$diagnosis ~. data = trainset,
method = "glm")
model1 <- train(diagnosis ~. data = trainset,
method = "glm")
model1 <- train(diagnosis ~. data = trainset, method = "glm")
model1 <- train(diagnosis ~ ., data = trainset, method = "glm")
preproc <- preProcess(trainset[, -1], method = "pca")
summary(preproc)
train_pca <- train(diagnosis ~ .,
data = trainset,
preProcess(trainset[, -1], method = "pca")
method = "glm")
train_pca <- train(diagnosis ~ .,
data = trainset,
preProcess(trainset[, -1], method = "pca"),
method = "glm")
preproc <- preProcess(trainset[, -1], method = "pca")
train_pca <- predict(preproc, trainset[, -1])
model2 <- train(trainset$diagnosis ~ .,
data = train_pca,
method = "glm")
train_pca <- data.frame(trainset[,1], predict(preproc, trainset[, -1]))
model2 <- train(diagnosis ~ .,
data = train_pca,
method = "glm")
str(train_pca)
colnames(train_pca)[1] <- "diagnosis"
model2 <- train(diagnosis ~ .,
data = train_pca,
method = "glm")
test_pca <- data.frame(testset[,1], predict(preproc, testset[, -1]))
colnames(test_pca)[1] <- "diagnosis"
model2_fit <- predict(model2, newdata = test_pca)
summary(model1)
summary(model2)
confusionMatrix(model1_fit, testset$diagnosis)
confusionMatrix(model2_fit, testset$diagnosis)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
trainset = data.frame(training$diagnosis, training[, startsWith(names(training), "IL")])
testset = data.frame(testing$diagnosis, testing[, startsWith(names(testing), "IL")])
colnames(trainset)[1] <- "diagnosis"
colnames(testset)[1] <- "diagnosis"
model1 <- train(diagnosis ~,
data = trainset,
method = "glm")
model1 <- train(diagnosis ~ .,
data = trainset,
method = "glm")
model1_fit <- predict(model1, newdata = testset)
names(trainset[,-1])
preproc <- preProcess(trainset[, -1], method = "pca")
train_pca <- data.frame(trainset[,1], predict(preproc, trainset[, -1]))
test_pca <- data.frame(testset[,1], predict(preproc, testset[, -1]))
colnames(train_pca)[1] <- "diagnosis"
colnames(test_pca)[1] <- "diagnosis"
model2 <- train(diagnosis ~ .,
data = train_pca,
method = "glm")
model2_fit <- predict(model2, newdata = test_pca)
summary(model1)
summary(model2)
confusionMatrix(model1_fit, testset$diagnosis)
confusionMatrix(model2_fit, testset$diagnosis)
data(mtcars)
mtcars$am[which(mtcars$am == 0)] <- "automatic"
mtcars$am[which(mtcars$am == 1)] <- "manual"
mtcars$am
knitr::opts_chunk$set(echo = TRUE)
data(mtcars)
mtcars$am[which(mtcars$am == 0)] <- "automatic"
mtcars$am[which(mtcars$am == 1)] <- "manual"
mtcars$am <- factor(mtcars$am)
data(mtcars)
mtcars$am[which(mtcars$am == 0)] <- "automatic"
mtcars$am[which(mtcars$am == 1)] <- "manual"
mtcars$am <- factor(mtcars$am)
plot(y = mtcars$mpg, x = mtcars$am)
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
mean(mtcars[mtcars$am == "manual"]$mpg)
mean(mtcars[mtcars$am == "manual", "mpg"])
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
mean(mtcars[mtcars$am == "manual", "mpg"])
mean(mtcars[mtcars$am == "automatic", "mpg"])
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
manual_mean = mean(mtcars[mtcars$am == "manual", "mpg"])
automatic_mean = mean(mtcars[mtcars$am == "automatic", "mpg"])
point(manual_mean)
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
manual_mean = mean(mtcars[mtcars$am == "manual", "mpg"])
automatic_mean = mean(mtcars[mtcars$am == "automatic", "mpg"])
points(manual_mean)
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
manual_mean = mean(mtcars[mtcars$am == "manual", "mpg"])
automatic_mean = mean(mtcars[mtcars$am == "automatic", "mpg"])
points(manual_mean, col = "red", pch = 18)
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
manual_mean = mean(mtcars[mtcars$am == "manual", "mpg"])
automatic_mean = mean(mtcars[mtcars$am == "automatic", "mpg"])
points(x = "manual", y = manual_mean, col = "red", pch = 18)
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
mean(mtcars[mtcars$am == "manual", "mpg"])
mean(mtcars[mtcars$am == "automatic", "mpg"])
mean(mtcars[mtcars$am == "manual", "mpg"])
mean(mtcars[mtcars$am == "automatic", "mpg"])
plot(y = mtcars$mpg, x = mtcars$am, xlab = "Transmission types", ylab = "MPG", main = "MPG by transmission types")
print("Mean mpgof manual :" &  mean(mtcars[mtcars$am == "manual", "mpg"]))
print("Mean mpgof manual :" +  mean(mtcars[mtcars$am == "manual", "mpg"]))
print("Mean mpgof manual :", mean(mtcars[mtcars$am == "manual", "mpg"]))
print(paste("Mean mpgof manual :", mean(mtcars[mtcars$am == "manual", "mpg"])))
mean(mtcars[mtcars$am == "automatic", "mpg"])
print(paste("Mean mpgof manual :", mean(mtcars[mtcars$am == "manual", "mpg"])))
print(paste("Mean mpgof automatic :", mean(mtcars[mtcars$am == "automatic", "mpg"]))
print(paste("Mean mpgof manual :", mean(mtcars[mtcars$am == "manual", "mpg"])))
print(paste("Mean mpg of automatic :", mean(mtcars[mtcars$am == "automatic", "mpg"]))
print(paste("Mean mpgof manual :", mean(mtcars[mtcars$am == "manual", "mpg"])))
print(paste("Mean mpg of automatic :", mean(mtcars[mtcars$am == "automatic", "mpg"])))
print(paste("Mean mpgof manual :", round(mean(mtcars[mtcars$am == "manual", "mpg"])), 1))
print(paste("Mean mpg of automatic :", mean(mtcars[mtcars$am == "automatic", "mpg"])))
print(paste("Mean mpgof manual :", round(mean(mtcars[mtcars$am == "manual", "mpg"])), 1))
print(paste("Mean mpg of automatic :", round(mean(mtcars[mtcars$am == "automatic", "mpg"])), 1))
reg_model = glm(mpg ~ am, data = mpg)
reg_model <- glm(mpg ~ am, data = mpg)
reg_model <- glm(mpg ~ am, data = mpg)
reg_model <- glm(mtcars$mpg ~ mtcars$am)
summary(reg_model)
reg_model <- glm(mtcars$mpg ~ mtcars$am -1)
summary(reg_model)
reg_model2 <- lm(mtcars$mpg ~ mtcars$am -1)
summary(reg_model2)
?influence.measures
influence.measures(fit)
rstandard(fit)
plot(rstandard(fit))
rstudent(fit)
plot(rstudent(fit))
hatvalues(fit)
plot(hatvalues(fit))
cooks.distance(fit)
plot(cooks.distance(fit))
vif(fit)
fit
vif(fit)
VIF(fit)
knitr::opts_chunk$set(echo = TRUE)
reg_model <- glm(mtcars$mpg ~ mtcars$am -1)
summary(reg_model)
reg_model <- glm(mtcars$mpg ~ mtcars$am)
summary(reg_model)
head(mtcars
)
cor(mtcars)
pairs(mtcars)
pairs(mtcars$mpg~.)
pairs(mtcars$mpg)
pairs(mtcars)
summary(fit)
fit <- lm(mtcars$mpg ~. -1)
fit <- lm(mpg ~. -1, data = mtcars)
summary(fit)
dfbetas(fit)
fit$coefficients
coefficients(fit)
summary(fit)$coefficients
fit <- lm(mpg ~., data = mtcars)
summary(fit)$coefficients
cor(mtcars$mpg, mtcars$cyl)
cor(mtcars$mpg, mtcars$cyl, mtcars$disp)
cor(mtcars$mpg, mtcars$gear)
fit <- lm(mpg ~.-1, data = mtcars)
summary(fit)$coefficients
reg_model <- glm(mtcars$mpg ~ mtcars$am)
summary(reg_model)$coefficients
dfbeta(fit)
cor(mtcars$mpg, mtcars$gear)
cor(mtcars$mpg, mtcars$wt)
cor(mtcars$mpg, mtcars$qsec)
cor(mtcars$mpg, mtcars$cyl)
cor(mtcars$mpg, mtcars$draft)
cor(mtcars$mpg, mtcars$drat)
mtcars[, is.numeric(mtcars)]
mtcars[, is.numeric(mtcars[,:])]
mtcars[, is.numeric(mtcars[:])]
nums <- unlist(lapply(mtcars, is.numeric))
cor(mtcars[,nums])
cor(mtcars[,nums])
cor(mtcars[,nums])[1,]
cor(mtcars[,nums])[,1]
cor(mtcars[,nums])[,1]
cor(mtcars[,nums])[,]
cor(mtcars[,nums])[1,]
fit1 <- lm(mpg ~ am, data = mtcars)
fit2 <- lm(mpg ~ am + wt, data = mtcars)
fit3 <- lm(mpg ~ am + wt + cyl, data = mtcars)
anova(fit1, fit2, fit3)
summary(fit3)
anova(fit1, fit2, fit3)
summary(fit3)
knitr::opts_chunk$set(echo = FALSE)
plot(fit3)
par(mfrow=(2,2)
par(mfrow=(2,2))
par(mfrow=c(2,2))
plot(fit3)
knitr::opts_chunk$set(echo = TRUE)
install.packages("xfun")
knitr::opts_chunk$set(echo = TRUE)
trainingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
if (!require("caret")) install.packages("caret", dependencies = TRUE)
library(caret)
install.packages("ggplot2", dependencies = TRUE)
if (!require("caret")) install.packages("caret", dependencies = TRUE)
library(caret)
library(ggplot2)
install.packages("pkgconfig")
library(ggplot2)
library(ggplot2)
dim(trainingData_raw)
dim(testingData_raw)
#count of non NA data of each column
col_na_num_train <-  apply(trainingData_raw, 2, function(x) sum(is.na(x) | x == ""))
col_na_num_test <-  colSums(is.na(testingData_raw) | testingData_raw == "")
# Columns of which N/A are greater than or equal to 90% to the number of rows
rem_col_train <- which(col_na_num_train / dim(trainingData_raw)[1] >= 0.9)
rem_col_test <- which(col_na_num_test / dim(testingData_raw)[1] >= 0.9)
# Remove columns with 90% NAs
trainingData_ <- trainingData_raw[, -rem_col_train]
testingData_ <- testingData_raw[, -rem_col_test]
# Remove non-obsvervation columns
trainingData <- trainingData_[, -c(1:7)]
testingData <- testingData_[, -c(1:7)]
dim(trainingData)
dim(testingData)
table(trainingData_raw$user_name, trainingData_raw$classe)
library(caret)
install.packages("lubricate")
library(caret)
install.packages("lubridateâ€™")
install.packages("lubridate")
install.packages("caret")
library(caret)
library(knitr)
model_nb <- train(classe ~., data = trainData, method = "naive_bayes")
trainData <- trainingData[trainDataIndex, ]
trainDataIndex <- createDataPartition(trainingData$classe, p = 0.6, list = FALSE)
trainData <- trainingData[trainDataIndex, ]
.libPaths()
install.packages("knitr")
install.packages("knitr")
install.packages("knitr")
knitr::opts_chunk$set(echo = TRUE)
trainDataIndex <- createDataPartition(trainingData$classe, p = 0.6, list = FALSE)
knitr::opts_chunk$set(echo = TRUE)
trainingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
library(caret)
library(ggplot2)
install.packages("ggplot2", dependencies = TRUE)
library(caret)
library(knitr)
library(caret)
library(ggplot2)
install.packages("colorspace")
library(caret)
install.packages("caret", dependencies = TRUE)
library(caret)
install.packages("purr")
install.packages("purrr")
library(caret)
install.packages("generics")
library(caret)
install.packages("lava")
library(caret)
library(knitr)
dim(trainingData_raw)
dim(testingData_raw)
#count of non NA data of each column
col_na_num_train <-  apply(trainingData_raw, 2, function(x) sum(is.na(x) | x == ""))
col_na_num_test <-  colSums(is.na(testingData_raw) | testingData_raw == "")
# Columns of which N/A are greater than or equal to 90% to the number of rows
rem_col_train <- which(col_na_num_train / dim(trainingData_raw)[1] >= 0.9)
rem_col_test <- which(col_na_num_test / dim(testingData_raw)[1] >= 0.9)
# Remove columns with 90% NAs
trainingData_ <- trainingData_raw[, -rem_col_train]
testingData_ <- testingData_raw[, -rem_col_test]
# Remove non-obsvervation columns
trainingData <- trainingData_[, -c(1:7)]
testingData <- testingData_[, -c(1:7)]
dim(trainingData)
dim(testingData)
table(trainingData_raw$user_name, trainingData_raw$classe)
trainDataIndex <- createDataPartition(trainingData$classe, p = 0.6, list = FALSE)
trainData <- trainingData[trainDataIndex, ]
testData <- trainingData[-trainDataIndex, ]
dim(trainData)
dim(testData)
install.packages("rattle", dependencies = TRUE)
library(rattle)
library(rattle)
fancyRpartPlot(model_ctree$finalModel)
knitr::opts_chunk$set(echo = TRUE)
# plotting the final model
plot(model_rf$finalModel, main = "Model error of Random Forest model by number of trees")
knitr::opts_chunk$set(echo = TRUE)
trainingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
trainingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
testingData_raw <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
library(caret)
library(knitr)
dim(trainingData_raw)
dim(testingData_raw)
#count of non NA data of each column
col_na_num_train <-  apply(trainingData_raw, 2, function(x) sum(is.na(x) | x == ""))
col_na_num_test <-  colSums(is.na(testingData_raw) | testingData_raw == "")
# Columns of which N/A are greater than or equal to 90% to the number of rows
rem_col_train <- which(col_na_num_train / dim(trainingData_raw)[1] >= 0.9)
rem_col_test <- which(col_na_num_test / dim(testingData_raw)[1] >= 0.9)
# Remove columns with 90% NAs
trainingData_ <- trainingData_raw[, -rem_col_train]
testingData_ <- testingData_raw[, -rem_col_test]
# Remove non-obsvervation columns
trainingData <- trainingData_[, -c(1:7)]
testingData <- testingData_[, -c(1:7)]
dim(trainingData)
dim(testingData)
table(trainingData_raw$user_name, trainingData_raw$classe)
trainDataIndex <- createDataPartition(trainingData$classe, p = 0.6, list = FALSE)
trainData <- trainingData[trainDataIndex, ]
testData <- trainingData[-trainDataIndex, ]
dim(trainData)
dim(testData)
model_ctree <- train(classe ~., data = trainData, method = "rpart")
library(rattle)
fancyRpartPlot(model_ctree$finalModel)
pred_ctree <- predict(model_ctree, newdata = testData)
confMatrix_ctree <- confusionMatrix(pred_ctree, testData$classe)
confMatrix_ctree
confMatrix_ctree$overall
model_rf <- train(classe ~., data = trainData, method = "rf")
model_rf <- train(classe ~., data = trainData, method = "rf")
model_nb <- train(classe ~., data = trainData, method = "naive_bayes")
pred_nb <- predict(model_nb, newdata = testData)
confMatrix_nb <- confusionMatrix(pred_nb, testData$classe)
confMatrix_nb
confMatrix_nb$overall
garbage <- capture.output(
model_gbm <- train(classe ~., data = trainData, method = "gbm")
)
pred_gbm <- predict(model_gbm, newdata = testData)
confMatrix_gbm <- confusionMatrix(pred_gbm, testData$classe)
confMatrix_gbm
confMatrix_gbm$overall
result_table <- data.frame(
Models = c("Classification Tree", "Random Forest", "Support Vector Machine", "Naive Bayes", "Stochastic Gradient Boosting"),
Accuracy = c(confMatrix_ctree$overall[1], confMatrix_rf$overall[1], confMatrix_svm$overall[1], confMatrix_nb$overall[1], confMatrix_gbm$overall[1])
)
final_pred_rf <- predict(model_rf, newdata = testingData)
knitr::opts_chunk$set(echo = TRUE)
starbucksData_ <- read.csv(file = "starbucks.csv", header = TRUE)
str(starbucksData_)
starbucksData <- subset(starbucksData_, starbucksData_$lat > 25 &  starbucksData_$lat < 30 & starbucksData_$long < -80 & starbucksData_$long > -82)
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map
if (!require("leaflet")) install.packages("leaflet")
if (!require("dplyr")) install.packages("dplyr")
library(leaflet)
library(dplyr)
starbucksData_ <- read.csv(file = "starbucks.csv", header = TRUE)
starbucksData <- subset(starbucksData_, starbucksData_$lat > 25 &  starbucksData_$lat < 30 & starbucksData_$long < -80 & starbucksData_$long > -82)
starbucksData_ <- read.csv(file = "starbucks.csv", header = TRUE)
starbucksData <- subset(starbucksData_, starbucksData_$lat > 25 &  starbucksData_$lat < 30 & starbucksData_$long < -80 & starbucksData_$long > -82)
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map
my_map <- leaflet() %>%
addTiles() %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map
str(starbucksData)
starbucksData$name <- as.character(starbucksData$name)
str(starbucksData)
head(starbucksData)
starbucksData_ <- read.csv(file = "starbucks.csv", header = TRUE)
starbucksData <- subset(starbucksData_, starbucksData_$lat > 25 &  starbucksData_$lat < 30 & starbucksData_$long < -80 & starbucksData_$long > -82)
head(starbucksData)
#starbucksData <- subset(starbucksData_, starbucksData_$lat > 25 &  starbucksData_$lat < 30 & starbucksData_$long < -80 & starbucksData_$long > -82)
starbucksData <- subset(starbucksData_, starbucksData_$lat > 25)
head(starbucksData)
head(starbucksData_)
range(starbucksData_$lat)
range(starbucksData_$long)
starbucksData_ <- read.csv(file = "starbucks.csv", header = TRUE)
starbucksData <- subset(starbucksData_, starbucksData_$lat > 25 &  starbucksData_$lat < 30 & starbucksData_$long < -80 & starbucksData_$long > -82)
starbucksData$name <- as.character(starbucksData$name)
head(starbucksData)
my_map <- leaflet() %>%
addTiles() %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map
my_map <- leaflet() %>%
addTiles() %>%
my_map <- my_map %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lng = starbucksData$lat, lat = starbucksData$long, popup = starbucksData$name)
my_map
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = starbucksData$name)
my_map
starbucksData <- subset(starbucksData_, starbucksData_$lat > 22 &  starbucksData_$lat < 35 & starbucksData_$long < -80 & starbucksData_$long > -82)
starbucksData$name <- as.character(starbucksData$name)
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = starbucksData$name)
my_map
starbucksData <- subset(starbucksData_, starbucksData_$lat > 22 &  starbucksData_$lat < 31 & starbucksData_$long < -80 & starbucksData_$long > -82)
starbucksData$name <- as.character(starbucksData$name)
my_map <- leaflet() %>%
addTiles()
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = starbucksData$name)
my_map
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = c(name)
my_map <- my_map %>%
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = name)
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = c(starbucksData$name, starbucksData$location))
my_map
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = paste(starbucksData$name, starbucksData$location))
my_map
my_map <- my_map %>%
addMarkers(data = starbucksData, lat = starbucksData$lat, lng = starbucksData$long, popup = paste(starbucksData$name, starbucksData$location), clusterOptions = markerClusterOptions())
my_map
install.packages('rsconnect')
install.packages("rsconnect")
rsconnect::setAccountInfo(name='jisun-kim',
token='363F05F58467BE5EDE10205B1858F6EA',
secret='<SECRET>')
rsconnect::setAccountInfo(name='jisun-kim',
token='363F05F58467BE5EDE10205B1858F6EA',
secret='wk20mfxcMCHDDDCUuUZ7y1WNfNArhonxPTFdE5Qm')
rm(list=ls())
rm(list = ls())
library(slidify)
library(devtools)
install.packages("devtools")
library(devtools)
install_github("slidify")
install_github("slidify", "ramnathv")
install_github(repo = "slidify", "ramnathv")
install_github('slidify', 'ramnathv')
install.packages("slidify")
install_github("slidify", "ramnathv")
install_github('ramnathv/slidify')
install_github('ramnathv/slidifyLibraries')
library(slidify)
author("shinyApp_project")
publish("jisunxkim", "shinyproject")
publish("jisunxkim", "shinyproject")
publish("jisunxkim", "shinyproject")
publish("jisunxkim", "shinyproject")
publish("jisunxkim", "shinyproject")
publish("jisunxkim", "shinyproject")
git config
publish("jisunxkim", "shinyproject")
publish("shinyproject", "jisunxkim")
publish(host="git")
publish(host="github")
publish("jisunxkim"/"shinyproject")
publish("jisunxkim/shinyproject")
publish(repo = "shinyproject", user = "jisunxkim")
